# Generative AI Intro

This 20-day introductory is designed to help you break into generative AI and is designed for today's busy individuals who crave concise, succinct information. 

If you've been wanting to learn about generative AI, understand the buzzwords, and not feel lost, you're in the right place. You can spend as little as 2-5 minutes a day learning generative AI in a way that builds on the knowledge gained from previous videos, giving you a comprehensive mind-map of the field. 

**1. The Busy Bee** 

If you're short on time but want to grasp generative AI concepts, my videos/reels are perfect for you. Just dedicate 2-5 minutes daily, and you'll stay informed without needing to look up extra material. Concepts will build on each other, keeping you perfectly in the loop.

**2. The Curious Learner**

If you liked the the videos but want to explore the concepts further, I've handpicked some great resources for you. These usually take about 20-30 minutes and will help you grasp the material more deeply. They'll also improve your understanding of related concepts, making everything more cohesive.

**3. The Hands-On Enthusiast**

If you're someone with a coding background who prefers hands-on learning, I'll be sharing few mini-project resources throughout the course. These projects will allow you to put the concepts into practice, using high-quality tutorials and videos.

🚨**NOTE: The videos stand alone, so you can understand the concepts without needing to read the additional resources—they're just there to aid your understanding.**

# What you'll Learn

This course heavily focuses on applied generative AI to help you get started with building applications. Here's an overview of the topics we'll cover, and if you don't understand some of these, don't worry—you'll get enough background during the course:

- Basics of Generative AI and Large Language Models (LLMs)
- Prompting Techniques
- Building Generative AI Applications (RAG)
- Basics of Fine-Tuning
- Common Challenges and Evaluation
- Future Trends in Generative AI

Please note that this course emphasizes understanding applied concepts and building applications using generative AI. It won't teach you to build generative AI models, which requires a much more comprehensive course structure and a lot of prerequisites. If someone tells you otherwise, I'd double-check their credentials 🙂

# What are the Prerequisites?

Honestly, this is a course I want people from all backgrounds to engage with and take away valuable insights at their preferred level of understanding. However, the amount of information you can absorb may vary depending on your background.

Here’s what it offers to individuals with different backgrounds:

### 1. No Computer Science (CS) Background

The course may introduce terms that are new to you and some parts might be challenging. However, you'll still gain a high-level overview of the field and understand key concepts. Based on my experience, you should be able to grasp about 60-80% of the content. It's still worth your 2-5 minutes daily, right?

### 2. CS Background, Limited Machine Learning (ML) Experience

If you're a software engineer or tech enthusiast, you probably have a basic understanding of ML concepts such as training and evaluation. You should be able to follow the course from beginning to end and complete a few projects in generative AI. My primary audience consists of individuals like you who are seeking to enter the field. This course can also serve as your entry into building generative AI projects and transitioning to a career as a generative AI engineer.

### 3. ML Background

If you have experience in ML but are new to NLP or LLMs, the main advantage for you will be the mini-projects and supplementary reading materials. These resources should provide you with enough knowledge to begin implementing your own projects and also enable you to start studying generative AI research and understand its broader context.

The videos will be available here everyday at 7:30 PM, Pacific Time

1. [Instagram](https://www.instagram.com/aish_reganti)
2. [YouTube](https://www.youtube.com/playlist?list=PLZoalK-hTD4VBBF03HAifKd6-DF68sYlC)


## 🗓️ Day 1: What is Generative AI 

---
**Key Topics**: AI, Generative AI, Neural Networks, Large Language Models(LLMs), Model Training

**Reading Material**:
- https://medium.com/womenintechnology/ai-c3412c5aa0ac

## 🗓️ Day 2: How are LLMs like ChatGPT Trained? 

---
**Key Topics**: Training, Fine-Tuning, Reinforcement Learning, Alignment

**Reading Material**:
- https://snorkel.ai/large-language-model-training-three-phases-shape-llm-training/

## 🗓️ Day 3: Basics of Prompt Engineering 

---
**Key Topics**: Prompting, Prompt Engineering

**Reading Material**:
- https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api


## 🗓️ Day 4: Advanced Prompt Engineering 
---
**Key Topics**: Chain of Thought Prompting, Self-Refine, Self-Consistency, Zero-Shot, Few-Shot

**Reading Material**:
- https://www.promptingguide.ai/techniques
- [Optional] [The Prompt Report: A Systematic Survey of Prompting Techniques](https://arxiv.org/pdf/2406.06608)

## 🗓️ Day 5: Automatic Prompt Engineering 
---
**Key Topics**: Meta Prompting, Automatic Prompt Engineeering

**Reading Material**:
- [Claude Meta Prompting Engine](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator)
- https://cobusgreyling.medium.com/automatic-prompt-engineering-907e230ece0

## 🗓️ Day 6: LLM Hallucinations and Causes 
---
**Key Topics**: Hallucinations, Sycophancy, Causes of Hallucinations

**Reading Material**:
- https://www.iguazio.com/glossary/llm-hallucination/

---
## 💻 Mini-Project 1 (Build a GPT-3.5 backed Chatbot)

In this mini-project, you'll complete a 1 hour course from Deeplearning.AI that can help you build a chatbot that does the following
- Summarizing (e.g., summarizing user reviews for brevity)
- Inferring (e.g., sentiment classification, topic extraction)
- Transforming text (e.g., translation, spelling & grammar correction)
- Expanding (e.g., automatically writing emails)

Prerequisites: Familiarity with Python

The course is completely free for everyone to take. Please find it [here](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)

Happy coding!!

---
## 🗓️ Day 7: Context Length 
---
**Key Topics**: Definition, Needle in a haystack test, Lost in the middle problem

**Reading Material**:
- https://agi-sphere.com/context-length/
---

## 🗓️ Day 8: Retrieval Augmented Generation (RAG) 
---
**Key Topics**: Basics, 4 Phases of RAG

**Reading Material**:
- https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/

---
## 🗓️ Day 9:What are embeddings? 
---
**Key Topics**: Word Vectors/Embeddings, Semantic Similarity, Embeddings in RAG

**Reading Material**:
- https://learn.microsoft.com/en-us/azure/architecture/ai-ml/guide/rag/rag-generating-embeddings

---
## 🗓️ Day 10:What are vector databases? 
---
**Key Topics**: Embeddings, Vector databases, Similarity search

**Reading Material**:
- https://www.pinecone.io/learn/vector-database/
---
## 🗓️ Day 11: LLM Evaluation 
---
**Key Topics**: Evaluation Dimensions

**Reading Material**:
- https://www.labellerr.com/blog/evaluating-large-language-models/#:~:text=To%20ensure%20a%20comprehensive%20evaluation,of%20a%20set%20of%20prompts.
---
## 🗓️ Day 12: Fine-Tuning
---
**Key Topics**: Definition, Resources

**Reading Material**:
- https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning

- https://www.superannotate.com/blog/llm-fine-tuning
  
**Notebooks and Coding Courses/Tutorials**:

- [Training & Fine-Tuning LLMs for Production](https://learn.activeloop.ai/courses/llms) by Activeloop
- [Finetuning Large Language Models](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/) by DeepLearning.AI
- [Tutorial to Fine-Tune Mistal on your own data](https://github.com/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb) by Brev.Dev

**Apps to generate AI videos (like the one I created)**
- https://www.heygen.com/
- https://www.synthesia.io/
- https://www.tryparrotai.com/
---
## 🗓️ Day 13: RLHF 
---
**Key Topics**: Definition, Alignment, Reward model

**Reading Material**:
- https://huggingface.co/blog/rlhf
  
---
## 🗓️ Day 14: LLM Agents 
---
**Key Topics**: Planning, Memory, Tools

**Reading Material**:
- https://developer.nvidia.com/blog/introduction-to-llm-agents/
---
## 🗓️ Day 15: Adversarial Attacks 
---
**Key Topics**: Jailbreaking, Attacks

**Reading Material**:
- https://www.discovermagazine.com/technology/adversarial-attack-makes-chatgpt-produce-objectionable-content
- Jailbreaking paper shown in the video ([link](https://chats-lab.github.io/persuasive_jailbreaker/))
---
## 🗓️ Day 16: Emerging AI Trends 
---
**Key Topics**: SLMs, Multimodal Models, Agents, Embodied AI

**Reading Material**:
- https://www.forbes.com/sites/janakirammsv/2024/01/02/exploring-the-future-5-cutting-edge-generative-ai-trends-in-2024/
- https://vmblog.com/archive/2023/12/14/kognic-2024-predictions-the-year-of-embodied-ai.aspx
---
## 🗓️ Day 17: Small Language Models
---
**Key Topics**: Knowledge distillation, Pruning, Quantization

**Reading Material**:
- https://aisera.com/blog/small-language-models/

---





